# -*- coding: utf-8 -*-
"""
LegalMate â€“ AI Legal Assistant (Hugging Face + FAISS)
èªªæ˜ï¼š
- å¾ data/sample_clauses.json è¼‰å…¥æ¢æ–‡
- ä½¿ç”¨ sentence-transformers ç”¢ç”Ÿå‘é‡ï¼Œåšå–®ä½å‘é‡æ­£è¦åŒ–ï¼ˆcosineï¼‰
- ä»¥ FAISS IndexFlatIPï¼ˆå…§ç©ï¼‰æª¢ç´¢æœ€ç›¸é—œæ¢æ–‡
- ç”¨ Hugging Face çš„ Flan-T5 ç”¢ç”Ÿæ¢æ–‡è§£é‡‹
- ä»¥ Gradio æä¾›ç°¡æ˜“ç¶²é ä»‹é¢
"""

import json
import numpy as np
import faiss
import gradio as gr
from pathlib import Path
from sentence_transformers import SentenceTransformer
from transformers import pipeline

# ------------------------------
# è·¯å¾‘è™•ç†ï¼šæœ¬æ©Ÿæœ‰ __file__ï¼ŒColab æ²’æœ‰
# ------------------------------
try:
    BASE_DIR = Path(__file__).parent
except NameError:
    BASE_DIR = Path.cwd()

DATA_PATH = BASE_DIR / "data" / "sample_clauses.json"

# ------------------------------
# è®€å– JSON å…§å®¹
# ------------------------------
if not DATA_PATH.exists():
    raise FileNotFoundError(f"Sample data not found at {DATA_PATH}. Please ensure data/sample_clauses.json exists.")

with open(DATA_PATH, "r", encoding="utf-8") as f:
    legal_docs = json.load(f)

if not isinstance(legal_docs, list) or not all(isinstance(x, str) for x in legal_docs):
    raise ValueError("data/sample_clauses.json å¿…é ˆæ˜¯ä¸€å€‹åªåŒ…å«å­—ä¸²çš„ listã€‚")

# ------------------------------
# å»ºç«‹ Embeddings + FAISS ç´¢å¼•ï¼ˆcosine ç›¸ä¼¼åº¦åšæ³•ï¼‰
# ------------------------------
embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

embeddings = embedder.encode(
    legal_docs,
    convert_to_numpy=True,        # ç¢ºä¿æ‹¿åˆ° numpyï¼Œè€Œä¸æ˜¯ list
    normalize_embeddings=True     # æŠŠå‘é‡æ­£è¦åŒ–ï¼ˆå–®ä½é•·åº¦ = 1ï¼‰
).astype("float32")               # FAISS åªåƒ float32

dimension = embeddings.shape[1]
index = faiss.IndexFlatIP(dimension)  # ç”¨å…§ç© (Inner Product)ï¼Œé…åˆæ­£è¦åŒ–ç­‰æ–¼ cosine
index.add(embeddings)

# ------------------------------
# æ–‡å­—ç”Ÿæˆæ¨¡å‹ï¼ˆå»ºè­°å…ˆç”¨ baseï¼›è¦æ›´å¼·å¯æ”¹ largeï¼‰
# ------------------------------
GEN_MODEL = "google/flan-t5-base"  # å¯æ”¹ç‚º "google/flan-t5-large"
qa_pipeline = pipeline("text2text-generation", model=GEN_MODEL)

# ------------------------------
# å•ç­”å‡½å¼
# ------------------------------
def search_and_answer(user_question: str) -> str:
    try:
        if not user_question or not user_question.strip():
            return "è«‹è¼¸å…¥å•é¡Œ / Please enter a question."

        query_vec = embedder.encode([user_question], convert_to_numpy=True, normalize_embeddings=True).astype("float32")
        scores, indices = index.search(query_vec, k=1)
        top_idx = int(indices[0][0])
        matched_clause = legal_docs[top_idx]

        prompt = (
            "You are a legal assistant for a U.S. law firm. "
            "Explain the following contract clause in clear, professional, plain English.\n\n"
            f"Clause:\n\"{matched_clause}\"\n\n"
            f"Question:\n{user_question}\n\n"
            "Answer:"
        )

        response = qa_pipeline(prompt, max_new_tokens=160, do_sample=False)[0]["generated_text"].strip()
        return "ğŸ“„ Matched clause:\n" + matched_clause + "\n\n" + "ğŸ’¡ Answer:\n" + response

    except Exception as e:
        return f"âŒ Error: {type(e).__name__}: {e}"

# ------------------------------
# Gradio ä»‹é¢
# ------------------------------
import gradio as gr

def launch_app(share=False, debug=False):
    demo = gr.Interface(
        fn=search_and_answer,
        inputs=gr.Textbox(lines=2, label="Enter your legal question:"),
        outputs=gr.Textbox(label="AI Answer"),
        title="LegalMate â€“ AI Legal Assistant (Hugging Face Version)"
    )
    demo.launch(share=share, debug=debug)

if __name__ == "__main__":
    # æœ¬æ©Ÿå»ºè­° share=Falseï¼›Colab æƒ³è¦å¤–ç¶²é€£çµå°±æ”¹æˆ True
    launch_app(share=True, debug=True)
